{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179f0928-b33f-4321-8c76-1d5335673d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install numpy\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0fd140-9e38-4dfd-8d09-6de935f291ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357665f4-57c2-4597-abc3-0bc4748c8d5b",
   "metadata": {},
   "source": [
    "## openpose 모델로드 및 gpu 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907ee0b6-ee18-4848-9c77-23b3133bceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device\n"
     ]
    }
   ],
   "source": [
    "device = \"gpu\" # please change it to \"gpu\" if the model needs to be run on cuda.\n",
    "\n",
    "protoFile = \"pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# COCO Output Format\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', \n",
    "                    'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip', \n",
    "                    'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16] ]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], \n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30], \n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56], \n",
    "          [37,38], [45,46]]\n",
    "\n",
    "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "if device == \"cpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "    print(\"Using CPU device\")\n",
    "elif device == \"gpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "    print(\"Using GPU device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9316b8-0f1a-4846-b6ea-df0a6d93dfc2",
   "metadata": {},
   "source": [
    "## openpose 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b53631-90a9-4635-80ac-114906f23bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Keypoints using Non Maximum Suppression on the Confidence Map\n",
    "def getKeypoints(probMap, threshold=0.1):\n",
    "    \n",
    "    mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "\n",
    "    mapMask = np.uint8(mapSmooth>threshold)\n",
    "    keypoints = []\n",
    "    \n",
    "    #find the blobs\n",
    "    contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #for each blob find the maxima\n",
    "    for cnt in contours:\n",
    "        blobMask = np.zeros(mapMask.shape)\n",
    "        blobMask = cv2.fillConvexPoly(blobMask, cnt, 1)\n",
    "        maskedProbMap = mapSmooth * blobMask\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)\n",
    "        keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "# Find valid connections between the different joints of a all persons present\n",
    "def getValidPairs(output, frameWidth, frameHeight, detected_keypoints):\n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    n_interp_samples = 10\n",
    "    paf_score_th = 0.1\n",
    "    conf_th = 0.7\n",
    "    # loop for every POSE_PAIR\n",
    "    for k in range(len(mapIdx)):\n",
    "        # A->B constitute a limb\n",
    "        pafA = output[0, mapIdx[k][0], :, :]\n",
    "        pafB = output[0, mapIdx[k][1], :, :]\n",
    "        pafA = cv2.resize(pafA, (frameWidth, frameHeight))\n",
    "        pafB = cv2.resize(pafB, (frameWidth, frameHeight))\n",
    "\n",
    "        # Find the keypoints for the first and second limb\n",
    "        candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
    "        candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "\n",
    "        # If keypoints for the joint-pair is detected\n",
    "        # check every joint in candA with every joint in candB \n",
    "        # Calculate the distance vector between the two joints\n",
    "        # Find the PAF values at a set of interpolated points between the joints\n",
    "        # Use the above formula to compute a score to mark the connection valid\n",
    "        \n",
    "        if( nA != 0 and nB != 0):\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            for i in range(nA):\n",
    "                max_j=-1\n",
    "                maxScore = -1\n",
    "                found = 0\n",
    "                for j in range(nB):\n",
    "                    # Find d_ij\n",
    "                    d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Find p(u)\n",
    "                    interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
    "                                            np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
    "                    # Find L(p(u))\n",
    "                    paf_interp = []\n",
    "                    for k in range(len(interp_coord)):\n",
    "                        paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
    "                                           pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) \n",
    "                    # Find E\n",
    "                    paf_scores = np.dot(paf_interp, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
    "                    \n",
    "                    # Check if the connection is valid\n",
    "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair  \n",
    "                    if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
    "                        if avg_paf_score > maxScore:\n",
    "                            max_j = j\n",
    "                            maxScore = avg_paf_score\n",
    "                            found = 1\n",
    "                # Append the connection to the list\n",
    "                if found:            \n",
    "                    valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
    "\n",
    "            # Append the detected connections to the global list\n",
    "            valid_pairs.append(valid_pair)\n",
    "        else: # If no keypoints are detected\n",
    "#             print(\"No Connection : k = {}\".format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "#     print(valid_pairs)\n",
    "    return valid_pairs, invalid_pairs\n",
    "\n",
    "# This function creates a list of keypoints belonging to each person\n",
    "# For each detected valid pair, it assigns the joint(s) to a person\n",
    "# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint\n",
    "def getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list):\n",
    "    # the last number in each row is the overall score \n",
    "    personwiseKeypoints = -1 * np.ones((0, 19))\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in invalid_pairs:\n",
    "            partAs = valid_pairs[k][:,0]\n",
    "            partBs = valid_pairs[k][:,1]\n",
    "            indexA, indexB = np.array(POSE_PAIRS[k])\n",
    "\n",
    "            for i in range(len(valid_pairs[k])): \n",
    "                found = 0\n",
    "                person_idx = -1\n",
    "                for j in range(len(personwiseKeypoints)):\n",
    "                    if personwiseKeypoints[j][indexA] == partAs[i]:\n",
    "                        person_idx = j\n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "                if found:\n",
    "                    personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
    "                    personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    # add the keypoint_scores for the two keypoints and the paf_score \n",
    "                    row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                    personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
    "    return personwiseKeypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a53e6a-e18a-4374-a7f6-074d1a235d8e",
   "metadata": {},
   "source": [
    "## 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9069f6f0-0de0-4c25-8aa8-9eac99586d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name 폴더 만들기\n",
    "def make_dir(root_dir, dir_name):\n",
    "    folder_list = []\n",
    "    for i in dir_name:\n",
    "        try: \n",
    "            if i not in folder_list:\n",
    "                print(\"{0}/{1}\".format(root_dir, i))\n",
    "                os.makedirs(\"{0}/{1}\".format(root_dir, i))\n",
    "                folder_list.append(dir_name)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e5c05-61e7-448a-a0ba-e623dae586a3",
   "metadata": {},
   "source": [
    "## 파일 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e977c428-e6aa-40ea-a849-b3a7d110bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import ntpath\n",
    "\n",
    "def find_file_fullname(fileDir):\n",
    "    file_name = []\n",
    "    for name in os.listdir(fileDir):\n",
    "        file_name.append(name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec98e6e-c132-4721-bb21-d4654445bb88",
   "metadata": {},
   "source": [
    "## 파트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7895971-9828-4242-b14c-d418b0a49186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_not_nan(key1, key2, idx, part_data, part_nan, part_seq):\n",
    "    if not np.isnan(key1) and not np.isnan(key2):\n",
    "        d = np.array([key1, key2, idx], dtype=np.float32)\n",
    "        part_data.append(d)\n",
    "        return 0\n",
    "    else:\n",
    "        part_nan += 1\n",
    "        if part_nan > 10: #오차 허용 프레임\n",
    "            if len(part_data) > 30:\n",
    "                append_seq_data(part_data, part_seq)\n",
    "                return 100\n",
    "            else:\n",
    "                return 15\n",
    "        return part_nan\n",
    "        \n",
    "def append_seq_data(part_data, part_seq):\n",
    "    seq_length = 30\n",
    "    part_data = np.array(part_data)\n",
    "    \n",
    "    for seq in range(len(part_data) - seq_length):\n",
    "        part_seq.append(part_data[seq:seq + seq_length])\n",
    "    part_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c26260-f987-45ae-bce2-24a89b47612d",
   "metadata": {},
   "source": [
    "## 영상 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02330f76-27c6-4961-a3b8-cca309efc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "def video_preprocessing(video_path, save_path, filename):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    data = []\n",
    "    position = []\n",
    "    last_position = []\n",
    "    final_position_index = -1\n",
    "    \n",
    "    ret, image1 = cap.read()\n",
    "    while cap.isOpened():\n",
    "        t0 = cv2.getTickCount()\n",
    "        if ret == False:\n",
    "            break\n",
    "            \n",
    "        frameWidth = image1.shape[1]\n",
    "        frameHeight = image1.shape[0]\n",
    "\n",
    "        # Fix the input Height and get the width according to the Aspect Ratio\n",
    "        inHeight = 368\n",
    "        inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "        inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "        net.setInput(inpBlob)\n",
    "        output = net.forward()\n",
    "\n",
    "        i = 0\n",
    "        probMap = output[0, i, :, :]\n",
    "        probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "        detected_keypoints = []\n",
    "        keypoints_list = np.zeros((0,3))\n",
    "        keypoint_id = 0\n",
    "        threshold = 0.1\n",
    "\n",
    "        for part in range(nPoints):\n",
    "            probMap = output[0,part,:,:]\n",
    "            probMap = cv2.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
    "            keypoints = getKeypoints(probMap, threshold)\n",
    "            keypoints_with_id = []\n",
    "            for i in range(len(keypoints)):\n",
    "                keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
    "                keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
    "                keypoint_id += 1\n",
    "\n",
    "            detected_keypoints.append(keypoints_with_id)\n",
    "\n",
    "        valid_pairs, invalid_pairs = getValidPairs(output, frameWidth, frameHeight, detected_keypoints)\n",
    "        personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list)\n",
    "        \n",
    "        \n",
    "        #사람 구분\n",
    "        detected_Obj = []\n",
    "        last_position += position\n",
    "        position = []\n",
    "        keylist = np.empty((len(personwiseKeypoints), 13, 2))\n",
    "\n",
    "        for i in range(1, 14):\n",
    "            for n in range(len(personwiseKeypoints)):\n",
    "                index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]\n",
    "                if -1 in index:\n",
    "                    continue\n",
    "                A = np.int32(keypoints_list[personwiseKeypoints[n][i].astype(int)])\n",
    "                keylist[n][i - 1] = A[:-1] #keylist는 목부터 발까지 좌표 값만 저장됨\n",
    "\n",
    "        for n in range(len(personwiseKeypoints)):\n",
    "            short_distance = 10000\n",
    "            if int(keylist[n][0][0]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                #여기서 벡터값 계산\n",
    "                joint = np.empty((13, 2))\n",
    "                for j in range(13):\n",
    "                    try:\n",
    "                        joint[j] = [keylist[n][j][0], keylist[n][j][1]]\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Compute angles between joints\n",
    "                v1 = joint[[0, 1, 2, 0, 4, 5, 0, 7, 8, 0, 10, 11], :2] # Parent joint\n",
    "                v2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], :2] # Child joint\n",
    "                v = v2 - v1 # [12, 2]\n",
    "                # Normalize v\n",
    "                v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Get angle using arcos of dot product\n",
    "                angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                    v[[0, 1, 3, 4, 6, 7, 9, 10],:], \n",
    "                    v[[1, 2, 4, 5, 7, 8, 10, 11],:]))\n",
    "\n",
    "                angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "                angle_label = np.array([angle], dtype=np.float32)\n",
    "\n",
    "                count = -1\n",
    "                last_p_index = -1\n",
    "                short_p_index = -1\n",
    "                for last_p in range(len(last_position)):\n",
    "                    temp_x = keylist[n][0][0] - last_position[last_p][0]\n",
    "                    temp_y = keylist[n][0][1] - last_position[last_p][1]\n",
    "                    temp_distance = temp_x * temp_x + temp_y * temp_y\n",
    "                    if temp_distance < short_distance:\n",
    "                        short_distance = temp_distance\n",
    "                        last_p_index = last_p\n",
    "                        position_index = last_position[last_p][2]\n",
    "                if last_p_index == -1:\n",
    "                    final_position_index+=1\n",
    "                    position.append([keylist[n][0][0], keylist[n][0][1], final_position_index, 0])\n",
    "\n",
    "                    angle_label = np.append(angle_label, final_position_index)\n",
    "                    detected_Obj.append(angle_label)\n",
    "                    #여기서 벡터 배열에 삽입\n",
    "                else:\n",
    "                    position.append([keylist[n][0][0], keylist[n][0][1], position_index, 0])\n",
    "                    del last_position[last_p_index]\n",
    "\n",
    "                    angle_label = np.append(angle_label, position_index)\n",
    "                    detected_Obj.append(angle_label)\n",
    "                    #여기서 벡터 배열에 삽입\n",
    "\n",
    "        data.append(detected_Obj)            \n",
    "\n",
    "        del_list = []         \n",
    "        for gone in range(len(last_position)):\n",
    "            last_position[gone][3] += 1\n",
    "            if last_position[gone][3] > 1:\n",
    "                del_list.append(last_position[gone])\n",
    "#         print(del_list)\n",
    "        if len(del_list) > 0:\n",
    "            for del_position in del_list:\n",
    "                last_position.remove(del_position)\n",
    "        \n",
    "        t1 = cv2.getTickCount()\n",
    "        ret, image1 = cap.read()\n",
    "        print (\"took %f seconds.\" % ((t1-t0)/cv2.getTickFrequency()))\n",
    "        \n",
    "    data = np.array(data)\n",
    "    np.save(os.path.join(save_path + 'p_video', f'raw_{filename}_'), data)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be0ce9-4f59-4f39-b116-0ac7504324fd",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5d0833-853c-4a96-a347-2a68e8db6152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing start\n",
      "kicking_k1.mp4\n",
      "took 0.945914 seconds.\n",
      "took 0.940451 seconds.\n",
      "took 0.925401 seconds.\n",
      "took 0.899472 seconds.\n",
      "took 0.887595 seconds.\n",
      "took 0.923927 seconds.\n",
      "took 0.915163 seconds.\n",
      "took 0.924900 seconds.\n",
      "took 0.940657 seconds.\n",
      "took 0.941468 seconds.\n",
      "took 0.927375 seconds.\n",
      "took 0.905199 seconds.\n",
      "took 0.925745 seconds.\n",
      "took 0.922372 seconds.\n",
      "took 0.891427 seconds.\n",
      "took 0.907708 seconds.\n",
      "took 0.905748 seconds.\n",
      "took 0.906652 seconds.\n",
      "took 0.939266 seconds.\n",
      "took 0.913194 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bver\\miniconda3\\envs\\ayo\\lib\\site-packages\\numpy\\linalg\\linalg.py:2506: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n",
      "c:\\users\\bver\\miniconda3\\envs\\ayo\\lib\\site-packages\\ipykernel_launcher.py:84: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.943156 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bver\\miniconda3\\envs\\ayo\\lib\\site-packages\\ipykernel_launcher.py:101: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.947364 seconds.\n",
      "took 0.924489 seconds.\n",
      "took 0.901105 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bver\\miniconda3\\envs\\ayo\\lib\\site-packages\\ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.912174 seconds.\n",
      "took 0.911668 seconds.\n",
      "took 0.890769 seconds.\n",
      "took 0.922733 seconds.\n",
      "took 0.899438 seconds.\n",
      "took 0.918575 seconds.\n",
      "took 0.901774 seconds.\n",
      "took 0.904219 seconds.\n",
      "took 1.014938 seconds.\n",
      "took 1.038443 seconds.\n",
      "took 1.018932 seconds.\n",
      "took 1.010668 seconds.\n",
      "took 1.011901 seconds.\n",
      "took 1.006629 seconds.\n",
      "took 1.018130 seconds.\n",
      "took 1.050119 seconds.\n",
      "took 1.040641 seconds.\n",
      "took 1.019151 seconds.\n",
      "took 1.047676 seconds.\n",
      "took 1.033180 seconds.\n",
      "took 1.025325 seconds.\n",
      "took 1.061356 seconds.\n",
      "took 1.030843 seconds.\n",
      "C:/Users/BVer/are_you_ok/datavideo/p_video/kicking_k1.mp4\n",
      "----- finish -----\n"
     ]
    }
   ],
   "source": [
    "now = '/p_video/'\n",
    "root_dir = 'C:/Users/BVer/are_you_ok'\n",
    "video_dir = root_dir + '/datavideo' + now\n",
    "\n",
    "try: #name 폴더 만들기\n",
    "    os.makedirs(\"./preprocessing\" + now)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "save_path = root_dir + \"/preprocessing/\"\n",
    "\n",
    "print('preprocessing start')\n",
    "video_name = []\n",
    "video_name = find_file_fullname(video_dir)\n",
    "for i in video_name:\n",
    "    video_path = video_dir + i\n",
    "    print(i)\n",
    "    video_preprocessing(video_path, save_path, i)\n",
    "    print(video_path)\n",
    "\n",
    "print('----- finish -----')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
