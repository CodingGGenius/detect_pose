{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5195d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install numpy\n",
    "# !pip install mediapipe opencv-python\n",
    "# !pip install pandas\n",
    "# !pip install xmltodict\n",
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c71a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68992907",
   "metadata": {},
   "source": [
    "## openpose 모델로드 및 gpu 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62cd72f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device\n"
     ]
    }
   ],
   "source": [
    "device = \"gpu\" # please change it to \"gpu\" if the model needs to be run on cuda.\n",
    "\n",
    "protoFile = \"pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# COCO Output Format\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', \n",
    "                    'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip', \n",
    "                    'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16] ]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], \n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30], \n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56], \n",
    "          [37,38], [45,46]]\n",
    "\n",
    "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "if device == \"cpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "    print(\"Using CPU device\")\n",
    "elif device == \"gpu\":\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "    print(\"Using GPU device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f34ea9",
   "metadata": {},
   "source": [
    "## openpose 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d264f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Keypoints using Non Maximum Suppression on the Confidence Map\n",
    "def getKeypoints(probMap, threshold=0.1):\n",
    "    \n",
    "    mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "\n",
    "    mapMask = np.uint8(mapSmooth>threshold)\n",
    "    keypoints = []\n",
    "    \n",
    "    #find the blobs\n",
    "    contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #for each blob find the maxima\n",
    "    for cnt in contours:\n",
    "        blobMask = np.zeros(mapMask.shape)\n",
    "        blobMask = cv2.fillConvexPoly(blobMask, cnt, 1)\n",
    "        maskedProbMap = mapSmooth * blobMask\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)\n",
    "        keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "# Find valid connections between the different joints of a all persons present\n",
    "def getValidPairs(output):\n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    n_interp_samples = 10\n",
    "    paf_score_th = 0.1\n",
    "    conf_th = 0.7\n",
    "    # loop for every POSE_PAIR\n",
    "    for k in range(len(mapIdx)):\n",
    "        # A->B constitute a limb\n",
    "        pafA = output[0, mapIdx[k][0], :, :]\n",
    "        pafB = output[0, mapIdx[k][1], :, :]\n",
    "        pafA = cv2.resize(pafA, (frameWidth, frameHeight))\n",
    "        pafB = cv2.resize(pafB, (frameWidth, frameHeight))\n",
    "\n",
    "        # Find the keypoints for the first and second limb\n",
    "        candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
    "        candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "\n",
    "        # If keypoints for the joint-pair is detected\n",
    "        # check every joint in candA with every joint in candB \n",
    "        # Calculate the distance vector between the two joints\n",
    "        # Find the PAF values at a set of interpolated points between the joints\n",
    "        # Use the above formula to compute a score to mark the connection valid\n",
    "        \n",
    "        if( nA != 0 and nB != 0):\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            for i in range(nA):\n",
    "                max_j=-1\n",
    "                maxScore = -1\n",
    "                found = 0\n",
    "                for j in range(nB):\n",
    "                    # Find d_ij\n",
    "                    d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Find p(u)\n",
    "                    interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
    "                                            np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
    "                    # Find L(p(u))\n",
    "                    paf_interp = []\n",
    "                    for k in range(len(interp_coord)):\n",
    "                        paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
    "                                           pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) \n",
    "                    # Find E\n",
    "                    paf_scores = np.dot(paf_interp, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
    "                    \n",
    "                    # Check if the connection is valid\n",
    "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair  \n",
    "                    if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
    "                        if avg_paf_score > maxScore:\n",
    "                            max_j = j\n",
    "                            maxScore = avg_paf_score\n",
    "                            found = 1\n",
    "                # Append the connection to the list\n",
    "                if found:            \n",
    "                    valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
    "\n",
    "            # Append the detected connections to the global list\n",
    "            valid_pairs.append(valid_pair)\n",
    "        else: # If no keypoints are detected\n",
    "            print(\"No Connection : k = {}\".format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "    print(valid_pairs)\n",
    "    return valid_pairs, invalid_pairs\n",
    "\n",
    "# This function creates a list of keypoints belonging to each person\n",
    "# For each detected valid pair, it assigns the joint(s) to a person\n",
    "# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint\n",
    "def getPersonwiseKeypoints(valid_pairs, invalid_pairs):\n",
    "    # the last number in each row is the overall score \n",
    "    personwiseKeypoints = -1 * np.ones((0, 19))\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in invalid_pairs:\n",
    "            partAs = valid_pairs[k][:,0]\n",
    "            partBs = valid_pairs[k][:,1]\n",
    "            indexA, indexB = np.array(POSE_PAIRS[k])\n",
    "\n",
    "            for i in range(len(valid_pairs[k])): \n",
    "                found = 0\n",
    "                person_idx = -1\n",
    "                for j in range(len(personwiseKeypoints)):\n",
    "                    if personwiseKeypoints[j][indexA] == partAs[i]:\n",
    "                        person_idx = j\n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "                if found:\n",
    "                    personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
    "                    personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    # add the keypoint_scores for the two keypoints and the paf_score \n",
    "                    row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                    personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
    "    return personwiseKeypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025bacd",
   "metadata": {},
   "source": [
    "## 폴더생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e79fd11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#name 폴더 만들기\n",
    "def make_dir(root_dir, dir_name):\n",
    "    folder_list = []\n",
    "    for i in dir_name:\n",
    "        try: \n",
    "            if i not in folder_list:\n",
    "                print(\"{0}/{1}\".format(root_dir, i))\n",
    "                os.makedirs(\"{0}/{1}\".format(root_dir, i))\n",
    "                folder_list.append(dir_name)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c0ebd",
   "metadata": {},
   "source": [
    "## 파일 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0812201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import ntpath\n",
    "\n",
    "def find_file_fullname(fileDir):\n",
    "    file_name = []\n",
    "    for name in os.listdir(fileDir):\n",
    "        file_name.append(name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd19fa",
   "metadata": {},
   "source": [
    "## csv 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb4820",
   "metadata": {},
   "source": [
    "## 영상 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2626871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.imread(\"C:/Users/BVer/are_you_ok/img/pose4.jpg\")\n",
    "# root_dir = \"C:/Users/BVer/are_you_ok\"\n",
    "# vid_dir = \"/video\"\n",
    "\n",
    "def video_preprocessing(root_dir, vid_dir, video_path, action_name, filename):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    framenumber = 0\n",
    "    while cap.isOpened():\n",
    "        data = []\n",
    "        ret, img = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        image1 = cv2.flip(img, 1)\n",
    "        # image1 = cv2.imread('C:/Users/BVer/are_you_o/img/5579.jpg')\n",
    "        frameWidth = image1.shape[1]\n",
    "        frameHeight = image1.shape[0]\n",
    "\n",
    "        if action_name == 'punching':\n",
    "            idx = 0\n",
    "        elif action_name == 'pushing':\n",
    "            idx = 1\n",
    "        elif action_name == 'kicking':\n",
    "            idx = 2\n",
    "        elif action_name == 'tread':\n",
    "            idx = 3\n",
    "\n",
    "        #t = time.time()\n",
    "\n",
    "        # Fix the input Height and get the width according to the Aspect Ratio\n",
    "        inHeight = 368\n",
    "        inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "        inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "        net.setInput(inpBlob)\n",
    "        output = net.forward()\n",
    "        #print(\"Time Taken = {}\".format(time.time() - t))\n",
    "\n",
    "        i = 0\n",
    "        probMap = output[0, i, :, :]\n",
    "        probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "        # plt.figure(figsize=[14,10])\n",
    "        # plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "        # plt.imshow(probMap, alpha=0.6)\n",
    "        # plt.colorbar()\n",
    "        # plt.axis(\"off\")\n",
    "\n",
    "        detected_keypoints = []\n",
    "        keypoints_list = np.zeros((0,3))\n",
    "        keypoint_id = 0\n",
    "        threshold = 0.1\n",
    "\n",
    "        for part in range(nPoints):\n",
    "            probMap = output[0,part,:,:]\n",
    "            probMap = cv2.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
    "        #     plt.figure()\n",
    "        #     plt.imshow(255*np.uint8(probMap>threshold))\n",
    "            keypoints = getKeypoints(probMap, threshold)\n",
    "    #         print(\"Keypoints - {} : {}\".format(keypointsMapping[part], keypoints))\n",
    "            keypoints_with_id = []\n",
    "            for i in range(len(keypoints)):\n",
    "                keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
    "                keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
    "                keypoint_id += 1\n",
    "\n",
    "            detected_keypoints.append(keypoints_with_id)\n",
    "\n",
    "\n",
    "        # if result.pose_landmarks is not None:\n",
    "        # for res in detected_keypoints:    \n",
    "        joint = np.zeros((18, 3))\n",
    "        for j in range(0, len(detected_keypoints)):\n",
    "            try:\n",
    "                joint[j] = [detected_keypoints[j][0][0], detected_keypoints[j][0][1], detected_keypoints[j][0][2]]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Compute angles between joints\n",
    "        v1 = joint[[0, 1, 1, 2, 3, 5, 6, 1, 8, 9, 1, 11, 12], :3] # Parent joint\n",
    "        v2 = joint[[1, 2, 5, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13], :3] # Child joint\n",
    "        v = v2 - v1 # [20, 3]\n",
    "        # Normalize v\n",
    "        v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Get angle using arcos of dot product\n",
    "        angle = np.arccos(np.einsum('nt,nt->n',\n",
    "            v[[0, 0, 1, 3, 2, 5, 1, 7, 8, 2, 10, 11],:], \n",
    "            v[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],:])) # [15,]\n",
    "\n",
    "        angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "        angle_label = np.array([angle], dtype=np.float32)\n",
    "        angle_label = np.append(angle_label, idx)\n",
    "\n",
    "        d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "        data.append(d)        \n",
    "        \n",
    "    data = np.array(data)\n",
    "    np.save(os.path.join('preprocessing/'+ action_name, f'raw_{action_name}_{filename}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    seq_length = 30\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    #     print(action_name, full_seq_data.shape)\n",
    "    np.save(os.path.join('preprocessing/'+ action_name, f'seq_{action_name}_{filename}'), full_seq_data)\n",
    "\n",
    "    framenumber += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0259e7",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf04f8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kicking', 'punching', 'pushing', 'tread']\n",
      "./preprocessing/kicking\n",
      "./preprocessing/punching\n",
      "./preprocessing/pushing\n",
      "./preprocessing/tread\n",
      "preprocessing start\n",
      "['kicking1c.mp4', 'kicking2c.mp4', 'kicking3c.mp4', 'kicking4c.mp4', 'kicking5c.mp4', 'kicking6c.mp4', 'kicking7c.mp4', 'kicking8c.mp4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chltp\\anaconda3\\envs\\areyouok\\lib\\site-packages\\ipykernel_launcher.py:83: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking1c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking2c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking3c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking4c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking5c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking6c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking7c.mp4\n",
      "kicking\n",
      "C:/Users/chltp/detect_video/datavideo/kicking/kicking8c.mp4\n",
      "['punching1.mp4', 'punching10.mp4', 'punching11.mp4', 'punching12.mp4', 'punching2.mp4', 'punching3.mp4', 'punching4.mp4', 'punching5.mp4', 'punching6.mp4', 'punching7.mp4', 'punching8.mp4', 'punching9.mp4']\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching1.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching10.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching11.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching12.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching2.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching3.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching4.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching5.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching6.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching7.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching8.mp4\n",
      "punching\n",
      "C:/Users/chltp/detect_video/datavideo/punching/punching9.mp4\n",
      "['pushing1.mp4', 'pushing10.mp4', 'pushing11.mp4', 'pushing12.mp4', 'pushing2.mp4', 'pushing3.mp4', 'pushing4.mp4', 'pushing5.mp4', 'pushing6.mp4', 'pushing7.mp4', 'pushing8.mp4', 'pushing9.mp4']\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing1.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing10.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing11.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing12.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing2.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing3.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing4.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing5.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing6.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing7.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing8.mp4\n",
      "pushing\n",
      "C:/Users/chltp/detect_video/datavideo/pushing/pushing9.mp4\n",
      "['thread1.mp4', 'thread2.mp4', 'thread3.mp4', 'thread4.mp4', 'thread5.mp4', 'thread6.mp4', 'thread7.mp4', 'thread8.mp4']\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread1.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread2.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread3.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread4.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread5.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread6.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread7.mp4\n",
      "tread\n",
      "C:/Users/chltp/detect_video/datavideo/tread/thread8.mp4\n",
      "----- finish -----\n"
     ]
    }
   ],
   "source": [
    "now = '/'\n",
    "root_dir = 'C:/Users/chltp/detect_video'\n",
    "video_dir = root_dir + '/datavideo' + now\n",
    "\n",
    "try: #name 폴더 만들기\n",
    "    os.makedirs(\"./preprocessing\" + now)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "action_list = []\n",
    "action_list = find_file_fullname(video_dir)\n",
    "print(action_list)\n",
    "make_dir(\"./preprocessing\", action_list)\n",
    "\n",
    "print('preprocessing start')\n",
    "for name in action_list:\n",
    "    video_name = []\n",
    "    video_name = find_file_fullname(video_dir+name)\n",
    "    print(video_name)\n",
    "    save_path = \"./preprocessing/\"+ name\n",
    "    for i in video_name:\n",
    "        video_path=video_dir+name+now+i\n",
    "        video_preprocessing(root_dir, video_dir, video_path, name, i)\n",
    "        print(name)\n",
    "        print(video_path)\n",
    "\n",
    "print('----- finish -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf89cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549b8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
